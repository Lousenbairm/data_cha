{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(\"/Users/kjx/Downloads/diabetes_data_upload.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diabetes.shape)\n",
    "print(diabetes.value_counts())\n",
    "print(diabetes.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = diabetes.replace(to_replace=['Yes', 'No', 'Male', 'Female', 'Positive', 'Negative'], value = [1,0, 1, 0, 1, 0])\n",
    "data.shape\n",
    "data.iloc[:, 0:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler((0,1))\n",
    "data_scaled2 = sc.fit_transform(data.iloc[:,0:16])\n",
    "print(data_scaled2)\n",
    "print(data[\"class\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.iloc[:, 0:16].values\n",
    "\n",
    "Y = data.iloc[:, 16].values\n",
    "\n",
    "\n",
    "X2 = data_scaled2\n",
    "print(X2)\n",
    "Y2 = data[\"class\"].values\n",
    "print(Y2)\n",
    "\n",
    "X2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting training data and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2, Y2, test_size = 0.3, random_state = 0, shuffle = True)\n",
    "X2_train[0].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training model using function\n",
    "\n",
    "def get_model(hiddenLayerOne = 6, dropout = 0.5, learnRate = 0.01):\n",
    "    # initialize a sequential model and add layer to flatten the\n",
    "\t# input data\n",
    "    model = tf.keras.models.Sequential()\n",
    "    #input tensor without affecting the batch size, flatten each batch in the input to 1 dimension\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(hiddenLayerOne, activation = 'relu', input_shape=X2_train[0].shape))\n",
    "    #Dropping out nodes to prevent overfitting\n",
    "    model.add(tf.keras.layers.Dropout(dropout))\n",
    "    #output\n",
    "    model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=learnRate), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#set seed\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "#no hyperparameter tuning\n",
    "fitting = model.fit(X2_train, Y2_train, validation_data=(X2_test, Y2_test), batch_size = 100, epochs = 300)\n",
    "\n",
    "\n",
    "\n",
    "#result\n",
    "print(\"Evaluating model ...\")\n",
    "accuracy = model.evaluate(X2_test, Y2_test)[1]\n",
    "print(\"accuracy: {: .2f}%\".format(accuracy * 100))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(fitting.history['loss'], label = 'train')\n",
    "plt.plot(fitting.history['val_loss'], label = 'test')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "#plt.show\n",
    "\n",
    "\n",
    "Y_pred = model.predict(X2_test)\n",
    "y_pred = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Y2_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitting.history['accuracy'], label = 'train')\n",
    "plt.plot(fitting.history['val_accuracy'], label = 'test')\n",
    "plt.ylabel('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "#plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##age: 68\n",
    "#gender: male\n",
    "#polyuria: no\n",
    "#polydipsia: no\n",
    "#sudden weight loss: no\n",
    "#weakness: yes\n",
    "#polyphagia: yes\n",
    "#genital thrush: no\n",
    "#visual blurring: yes\n",
    "#itching: no\n",
    "#irritability: no\n",
    "#delayed healing: no\n",
    "#partial paresis: no\n",
    "#muscle stiffness: no\n",
    "#alopecia: no\n",
    "#obesity: no\n",
    "\n",
    "new = np.array([48, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
    "new2 = new.reshape(1, -1)\n",
    "new3 = sc.transform(new2)\n",
    "\n",
    "\n",
    "\n",
    "print(new3)\n",
    "\n",
    "model.predict(new3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, show_layer_names= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model(hiddenLayerOne = 16, dropout = 0.3, learnRate = 0.01)\n",
    "\n",
    "#no hyperparameter tuning\n",
    "fitting = model.fit(X2_train, Y2_train, validation_data=(X2_test, Y2_test), batch_size = 90, epochs = 250)\n",
    "\n",
    "plt.plot(fitting.history['loss'], label = 'train')\n",
    "plt.plot(fitting.history['val_loss'], label = 'test')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitting.history['accuracy'], label = 'train')\n",
    "plt.plot(fitting.history['val_accuracy'], label = 'test')\n",
    "plt.ylabel('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow hypermeter tuning\n",
    "#KerasClassifier make it compatible with scikit - learn function (for hyperparameter turning)\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#scaled data\n",
    "print(X2_test, X2_train, Y2_test, Y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "#wrap model first\n",
    "model = KerasClassifier(build_fn=get_model, verbose = 0)\n",
    "\n",
    "#define grid search space\n",
    "hiddenLayerOne = [6,8,10,12]\n",
    "learnRate = [1e-2, 1e-3, 1e-4]\n",
    "dropout = [0.3, 0.4, 0.5]\n",
    "batchSize = [30, 40, 50, 60, 70, 80, 90, 100]\n",
    "epochs = [50, 100, 150, 200, 250, 300, 350, 400]\n",
    "\n",
    "#create dictionary for the grid\n",
    "grid = dict(\n",
    "    hiddenLayerOne = hiddenLayerOne,\n",
    "    learnRate = learnRate,\n",
    "    dropout = dropout,\n",
    "    batch_size = batchSize,\n",
    "    epochs = epochs\n",
    ")\n",
    "\n",
    "# initialize a random search with a 3-fold cross-validation and then\n",
    "# start the hyperparameter search process\n",
    "\n",
    "print(\"Random Search ...\")\n",
    "searcher = RandomizedSearchCV(estimator= model, n_jobs= 1, cv = 3, param_distributions= grid, scoring = \"accuracy\")\n",
    "searchResults = searcher.fit(X2_train, Y2_train)\n",
    "\n",
    "#summarise grid search info\n",
    "bestScore = searchResults.best_score_\n",
    "bestPara = searchResults.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,\n",
    "\tbestPara))\n",
    "\n",
    "\n",
    "#plotting loss \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sklearn\n",
    "sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the best model, make predictions on our data, and show a\n",
    "# classification report\n",
    "print(\"[INFO] evaluating the best model...\")\n",
    "bestModel = searchResults.best_estimator_\n",
    "\n",
    "accuracy = bestModel.score(X2_test, Y2_test)\n",
    "print(\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model(hiddenLayerOne = 16, dropout = 0.4, learnRate = 0.01)\n",
    "\n",
    "#set seed\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "#after hyperparameter tuning\n",
    "fitting = model.fit(X2_train, Y2_train, validation_data=(X2_test, Y2_test), batch_size = 70, epochs = 350)\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, show_layer_names= True)\n",
    "\n",
    "plt.plot(fitting.history['loss'], label = 'train')\n",
    "plt.plot(fitting.history['val_loss'], label = 'test')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitting.history['accuracy'], label = 'train')\n",
    "plt.plot(fitting.history['val_accuracy'], label = 'test')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the ANN\n",
    "ann = tf.keras.models.Sequential()\n",
    "\n",
    "#add the input layer and first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units = 16, activation = 'relu', input_shape=X_train[0].shape))\n",
    "\n",
    "#add output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "#First attempt, 16, 16, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training ann\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "fitting = ann.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size = 40, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting loss \n",
    "\n",
    "plt.plot(fitting.history['loss'], label = 'train')\n",
    "plt.plot(fitting.history['val_loss'], label = 'test')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(ann, show_shapes=True, show_layer_names= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the ANN\n",
    "ann_2 = tf.keras.models.Sequential()\n",
    "\n",
    "#add the input layer and first hidden layer\n",
    "ann_2.add(tf.keras.layers.Dense(units = 14, activation = 'relu', input_shape=X_train[0].shape))\n",
    "\n",
    "#add output layer\n",
    "ann_2.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "#Second Attempt attempt, 16, 14, 1\n",
    "\n",
    "#training ann\n",
    "\n",
    "ann_2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "fitting_2 = ann_2.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size = 40, epochs = 100)\n",
    "\n",
    "#plotting loss \n",
    "\n",
    "plt.plot(fitting_2.history['loss'], label = 'train')\n",
    "plt.plot(fitting_2.history['val_loss'], label = 'test')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = ann_2.evaluate(X_test, Y_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "plot_model(ann_2, show_shapes=True, show_layer_names= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_pred = ann_2.predict(X_test)\n",
    "y_pred = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the ANN\n",
    "ann_3 = tf.keras.models.Sequential()\n",
    "\n",
    "#add the input layer and first hidden layer\n",
    "ann_3.add(tf.keras.layers.Dense(units = 8, activation = 'relu', input_shape=X_train[0].shape))\n",
    "\n",
    "ann_3.add(tf.keras.layers.Dense(units=8, activation='relu'))\n",
    "\n",
    "#add output layer\n",
    "ann_3.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "#Second Attempt attempt, 16, 16, 16, 1\n",
    "\n",
    "#training ann\n",
    "\n",
    "ann_3.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "fitting_3 = ann_3.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size = 40, epochs = 100)\n",
    "\n",
    "#plotting loss \n",
    "\n",
    "plt.plot(fitting_3.history['loss'], label = 'train')\n",
    "plt.plot(fitting_3.history['val_loss'], label = 'test')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def ann_two():\n",
    "\n",
    "    #initializing the ANN\n",
    "    ann_2 = tf.keras.models.Sequential()\n",
    "\n",
    "    #add the input layer and first hidden layer\n",
    "    ann_2.add(tf.keras.layers.Dense(units = 16, activation = 'relu', input_shape=X_train[0].shape))\n",
    "\n",
    "    ann_2.add(tf.keras.layers.Dense(units=16, activation='relu'))\n",
    "\n",
    "    #add output layer\n",
    "    ann_2.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    #Second Attempt attempt, 16, 16, 16, 1\n",
    "\n",
    "    #training ann\n",
    "\n",
    "    ann_2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return ann_2\n",
    "\n",
    "keras_2 = KerasClassifier(build_fn = ann_two)\n",
    "\n",
    "scores = cross_val_score(keras_2, X, Y, cv=10, scoring='accuracy')\n",
    "print(scores)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_one():\n",
    "    #initializing the ANN\n",
    "    ann = tf.keras.models.Sequential()\n",
    "\n",
    "    #add the input layer and first hidden layer\n",
    "    ann.add(tf.keras.layers.Dense(units = i, activation = 'relu', input_shape=X_train[0].shape))\n",
    "\n",
    "    #add output layer\n",
    "    ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return ann\n",
    "\n",
    "keras_1 = KerasClassifier(build_fn = ann_one)\n",
    "\n",
    "scores_1 = cross_val_score(keras_1, X, Y, cv=10, scoring='accuracy')\n",
    "print(scores_1)\n",
    "\n",
    "print(scores_1.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 3)\n",
    "\n",
    "for train_index, test_index in kf.split(X2):\n",
    "    X2_train, X2_test = X2[train_index], X2[test_index]\n",
    "    Y2_train, Y2_test = Y2[train_index], Y2[test_index]\n",
    "\n",
    "    fitting =  model.fit(X2_train, Y2_train, validation_data=(X_test, Y_test), batch_size = 30, epochs = 400)\n",
    "\n",
    "    plt.plot(fitting.history['accuracy'], label = 'train')\n",
    "    plt.ylabel('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show\n",
    "\n",
    "    plt.plot(fitting.history['val_accuracy'], label = 'test')\n",
    "    plt.ylabel('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show\n",
    "\n",
    "    print(\"train_acc: \", np.mean(fitting.history['accuracy']))\n",
    "    print(\"test_acc: \", np.mean(fitting.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def ann_one(activation='relu', optimizer='adam'):\n",
    "    #initializing the ANN\n",
    "    ann = tf.keras.models.Sequential()\n",
    "\n",
    "    #add the input layer and first hidden layer\n",
    "    ann.add(tf.keras.layers.Dense(units = 14, activation = activation, input_shape=X_train[0].shape))\n",
    "\n",
    "    #add output layer\n",
    "    ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    ann.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return ann\n",
    "\n",
    "keras_1 = KerasClassifier(build_fn = ann_one)\n",
    "\n",
    "\n",
    "\n",
    "accuracies = cross_val_score(estimator=keras_1, scoring=\"accuracy\", \n",
    "    X=X_train, y=Y_train, cv=10)\n",
    "\n",
    "print(accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the ANN\n",
    "ann_2 = tf.keras.models.Sequential()\n",
    "\n",
    "#add the input layer and first hidden layer\n",
    "ann_2.add(tf.keras.layers.Dense(units = 14, activation = 'relu', input_shape=X2_train[0].shape))\n",
    "\n",
    "#add output layer\n",
    "ann_2.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "#Second Attempt attempt, 16, 14, 1\n",
    "\n",
    "#training ann\n",
    "\n",
    "ann_2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "fitting_2 = ann_2.fit(X2_train, Y2_train, validation_data=(X2_test, Y2_test), batch_size = 40, epochs = 100)\n",
    "\n",
    "#plotting loss \n",
    "\n",
    "plt.plot(fitting_2.history['loss'], label = 'train')\n",
    "plt.plot(fitting_2.history['val_loss'], label = 'test')\n",
    "plt.ylabel('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
